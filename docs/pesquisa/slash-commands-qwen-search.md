# De Plugins a Regras Internas: Um Guia Comparativo sobre a Personalização de Comandos Slash em CLIs de IA

## Mecanismos de Extensibilidade em Qwen Code e Claude Code: Um Modelo Baseado em Plugins e Arquivos

A análise dos mecanismos de extensibilidade de comandos slash em Qwen Code e Claude Code revela duas abordagens sofisticadas e robustas, embora distintas, que colocam essas ferramentas na vanguarda da customização de interfaces de linha de comando de inteligência artificial. Ambas as plataformas movem-se além de um modelo monolítico, oferecendo caminhos estruturados para que os usuários e desenvolvedores possam expandir as capacidades padrão do assistente de IA. Qwen Code demonstra um sistema de extensibilidade mais explícito e modular, enquanto Claude Code apresenta um modelo híbrido que combina funcionalidades avançadas com métodos de personalização mais diretos. A investigação detalhada desses dois sistemas, fundamentada na documentação oficial e em discussões comunitárias, fornece uma visão clara de como a personalização pode ser alcançada de forma acessível e poderosa.

Qwen Code estabelece sua filosofia de extensibilidade desde a arquitetura fundamental, projetando seu sistema para ser aberto e integrável [[49](https://qwenlm.github.io/qwen-code-docs/en/developers/architecture/)]. A plataforma não apenas suporta a adição de novas funcionalidades, mas promove explicitamente essa prática como um pilar central de seu design. A documentação técnica descreve o sistema de ferramentas como algo concebido para ser extensível, permitindo que novas capacidades sejam introduzidas através de "ferramentas personalizadas" ou integrações com servidores Model Context Protocol (MCP) [[49](https://qwenlm.github.io/qwen-code-docs/en/developers/architecture/)]. Essa dualidade de abordagem — ferramentas nativas e integração com ecossistemas externos — demonstra um compromisso com a interoperabilidade e a escalabilidade, alinhando-se às necessidades tanto de usuários individuais quanto de equipes e organizações que buscam conectar o Qwen Code a seus próprios sistemas proprietários ou a serviços de terceiros. O próprio protocolo MCP é descrito como uma maneira de conectar o Qwen Code a centenas de ferramentas e fontes de dados externas, destacando a importância estratégica da conectividade para a plataforma [[50](https://docs.anthropic.com/en/docs/claude-code/mcp)].

Um dos mecanismos de extensibilidade mais notáveis e acessíveis do Qwen Code é a capacidade de criar comandos personalizados diretamente através de arquivos de texto formatado em Markdown. A documentação oferece guias completos para esta funcionalidade, como "Começar usando Qwen Code Extension" e "Getting Started with Qwen Code Extensions", que orientam os usuários a configurar um novo diretório de extensão e a criar comandos personalizados [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/), [45](https://qwenlm.github.io/qwen-code-docs/en/developers/extensions/getting-started-extensions/)]. Este método é extremamente democratizador, pois não exige conhecimento de programação ou a construção de uma extensão completa; basta ao usuário escrever um prompt bem elaborado dentro de um arquivo `.md` localizado em um diretório específico, como `.qwen/commands/` [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/)]. Ao fazer isso, o conteúdo do arquivo Markdown é automaticamente exposto como um novo comando slash dentro da sessão interativa do CLI. Esta abordagem simplifica drasticamente a personalização, permitindo que qualquer pessoa que compreenda o funcionamento de prompts de IA possa criar atalhos poderosos para tarefas recorrentes ou especializadas. A documentação também destaca a criação de comandos personalizados como parte de um processo maior de desenvolvimento de extensões, indicando que este é um componente fundamental do ecossistema de extensões do Qwen Code [[45](https://qwenlm.github.io/qwen-code-docs/en/developers/extensions/getting-started-extensions/)].

Para gerenciar dinamicamente essas extensões e comandos, o Qwen Code incorpora um sistema de gerenciamento interno. Os usuários podem utilizar o comando slash `/extensions` diretamente dentro da interface do CLI para visualizar, instalar, desinstalar e atualizar extensões [[11](https://qwenlm.github.io/qwen-code-docs/en/users/extension/introduction/), [14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)]. Uma característica crucial desta funcionalidade é o suporte à "recarga em tempo real" ("hot reload") [[14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)]. Isso significa que as modificações feitas em arquivos de extensão ou comandos personalizados são aplicadas imediatamente, sem a necessidade de reiniciar o aplicativo ou a sessão de CLI [[14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)]. Essa capacidade de recarregamento instantâneo é um diferencial significativo para a produtividade, pois elimina o tempo de espera e permite um ciclo de desenvolvimento e teste muito mais rápido e iterativo. O usuário pode editar um comando Markdown, salvar o arquivo e já utilizá-lo no mesmo terminal, recebendo feedback quase que instantaneamente. Esta integração perfeita entre a criação de conteúdo (Markdown) e o ambiente de execução (CLI) demonstra um design cuidadoso que prioriza a fluidez do fluxo de trabalho do desenvolvedor.

Além dos comandos simples baseados em Markdown, o Qwen Code permite uma personalização ainda mais profunda através de suas extensões, que podem incluir componentes mais complexos. As extensões podem fornecer agentes secundários personalizados, que ficam disponíveis quando a extensão é ativada [[37](https://qwenlm.github.io/qwen-code-docs/en/users/features/sub-agents/)]. Esses subagentes são armazenados em um diretório `agents/` dentro do pacote da extensão, sugerindo um nível de encapsulamento e modularidade que vai além de simplesmente definir prompts [[37](https://qwenlm.github.io/qwen-code-docs/en/users/features/sub-agents/)]. Mais importante ainda é a capacidade de uma extensão adicionar "ferramentas personalizadas" através de uma integração com um servidor MCP [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/)]. Um servidor MCP funciona como uma ponte, permitindo que o Qwen Code invoque funções e obtenha dados de sistemas externos em resposta a consultas de IA [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/)]. Por exemplo, uma extensão poderia conectar o Qwen Code a uma API interna da empresa, um banco de dados ou uma ferramenta de CI/CD, transformando o assistente de IA em um agente capaz de executar ações práticas no mundo real. A documentação sobre servidores MCP fornece um guia detalhado sobre como configurar e usar esses servidores, mostrando que esta é uma funcionalidade central e bem apoiada pela plataforma [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/)]. A combinação de comandos Markdown acessíveis, gerenciamento de extensões intuitivo e um ecossistema de integração via MCP torna o Qwen Code uma das plataformas mais flexíveis e potentes disponíveis para extensibilidade.

Claude Code, por outro lado, adota um modelo de extensibilidade híbrido, combinando funcionalidades nativas prontas para uso com um poderoso sistema de extensão chamado "Skills". A documentação principal do Claude Code enfatiza a criação, gestão e compartilhamento de Skills como a principal forma de estender as capacidades do Claude Code [[7](https://docs.anthropic.com/en/docs/claude-code/skills)]. Os Skills são descritos como a forma de codificar conhecimento específico da equipe ou domínio, instruções contextuais e até mesmo interações automatizadas, tudo o que pode ser encapsulado em um pacote compartilhável [[46](https://dev.to/rajeshroyal/plugins-share-your-entire-claude-code-setup-with-one-command-294n)]. Embora a documentação seja predominantemente focada nos Skills, eles frequentemente se manifestam para o usuário final como comandos slash personalizados. Um Skill pode definir um conjunto de instruções e contexto tão específico que, quando invocado, ele se comporta exatamente como um comando slash altamente especializado.

Contudo, uma análise mais aprofundada das fontes revela um segundo mecanismo de extensibilidade, talvez menos documentado inicialmente, mas igualmente poderoso: a criação de comandos slash personalizados a partir de arquivos Markdown. Um insight crucial foi encontrado no arquivo de alterações da biblioteca `anthropics/claude-code`, que afirma explicitamente: "Arquivos Markdown em diretórios `.claude/commands/` agora aparecem como comandos slash personalizados para inserir prompts em sua conversa" [[69](https://docs.anthropic.com/en/release-notes/claude-code)]. Esta funcionalidade, embora mencionada brevemente, indica que, assim como o Qwen Code, o Claude Code suporta um método de personalização extremamente acessível que não requer codificação. O usuário pode simplesmente criar um arquivo, por exemplo, `.claude/commands/debug.md`, e preencher seu conteúdo com um prompt detalhado para depuração de código. Ao digitar `/debug` na interface de chat, o conteúdo desse arquivo seria inserido no campo de prompt, efetivamente criando um comando personalizado [[15](https://dev.to/diet-code103/claude-code-is-a-beast-tips-from-6-months-of-hardcore-use-572n)]. A beleza dessa abordagem reside na expansão dos comandos slash em prompts completos, permitindo que o usuário empacote uma quantidade substancial de contexto e instruções em um único comando curto [[15](https://dev.to/diet-code103/claude-code-is-a-beast-tips-from-6-months-of-hardcore-use-572n)]. Este método é particularmente útil para tarefas complexas que exigiriam muitos parâmetros ou um longo texto de instrução caso fossem digitadas manualmente.

A estratégia do Claude Code parece, portanto, dupla. Por um lado, ele promove a criação de Skills como uma solução mais sofisticada e compartilhável, ideal para equipes que desejam padronizar e distribuir conhecimento especializado. Por outro, a existência de um método baseado em Markdown simplifica drasticamente a personalização para o usuário individual, oferecendo uma porta de entrada de baixa barreira. A documentação menciona outros arquivos de configuração, como `CLAUDE.md` ou `.claude/CLAUDE.md`, que podem ser usados para fornecer contexto de projeto e instruções gerais ao modelo [[10](https://docs.anthropic.com/en/docs/claude-code/sdk)]. Embora não seja um comando slash, essa capacidade de injetar contexto de alto nível é uma forma fundamental de personalizar o comportamento geral do assistente. Além disso, o Claude Code oferece um recurso chamado "Hooks", que permite automatizar workflows [[8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)]. Os Hooks permitem que o usuário configure o Claude Code para executar comandos shell automaticamente quando certas ações ocorrem, como quando o Claude Code edita um arquivo, termina uma tarefa ou precisa de mais informações [[8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)]. Por exemplo, um hook poderia ser configurado para formatar o código automaticamente após uma edição do modelo ou para enviar uma notificação quando uma tarefa for concluída [[8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)]. Essa capacidade de automação e interação com o ambiente de desenvolvimento exterior eleva o Claude Code de um simples assistente de conversação para um agente autônomo que pode participar ativamente do fluxo de trabalho do desenvolvedor.

Em resumo, tanto o Qwen Code quanto o Claude Code oferecem caminhos robustos e bem definidos para a extensibilidade de comandos slash. O Qwen Code opta por um modelo mais explícito e modular, com um sistema de extensões claro que suporta desde comandos simples baseados em Markdown até integrações complexas via MCP. O Claude Code, por sua vez, adota uma abordagem híbrida, combinando um sistema de "Skills" para compartilhamento de conhecimento com um método acessível baseado em Markdown para personalização rápida e um poder de automação via "Hooks". Ambas as abordagens representam um avanço significativo em relação a ferramentas de IA mais fechadas, concedendo aos desenvolvedores o poder de moldar suas ferramentas de IA para se ajustarem perfeitamente a seus fluxos de trabalho, linguagens e domínios de conhecimento específicos.

| Métrica | Qwen Code | Claude Code |
| :--- | :--- | :--- |
| **Mecanismo Principal** | Sistema de Extensões (Plugins) e Comandos via Markdown [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/)] | Híbrido: Skills e Comandos via Markdown [[69](https://docs.anthropic.com/en/release-notes/claude-code)] |
| **Método Acessível** | Arquivos Markdown em `.qwen/commands/*.md` [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/)] | Arquivos Markdown em `.claude/commands/*.md` [[69](https://docs.anthropic.com/en/release-notes/claude-code)] |
| **Gerenciamento de Extensões** | Comando `/extensions` com recarga em tempo real [[14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)] | Gerenciamento de Skills (documentação principal) [[7](https://docs.anthropic.com/en/docs/claude-code/skills)] |
| **Integração Avançada** | Servidores Model Context Protocol (MCP) [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/)] | Conexão a ferramentas via MCP [[50](https://docs.anthropic.com/en/docs/claude-code/mcp)] |
| **Automação** | Não especificado | Hooks para executar comandos shell [[8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)] |
| **Fonte-Chave** | Documentação oficial, tutoriais, changelog [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/), [48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/), [69](https://docs.anthropic.com/en/release-notes/claude-code)] | Documentação oficial, fóruns comunitários [[7](https://docs.anthropic.com/en/docs/claude-code/skills), [8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide), [69](https://docs.anthropic.com/en/release-notes/claude-code)] |

## Customização Interna no Cursor IDE/CLI: O Poder das Regras de Usuário

Enquanto outras ferramentas de IA para desenvolvimento de software se concentram em modelos de extensibilidade baseados em plugins, arquivos externos ou integrações com sistemas externos, o Cursor IDE/CLI adota uma abordagem única e distintiva. Em vez de externalizar a lógica de personalização, o Cursor integra profundamente esse processo diretamente dentro do próprio editor de código. A principal metodologia para adicionar comandos slash personalizados no Cursor é através de um recurso chamado "User Rules" (Regras de Usuário), que pode ser acessado e configurado através do menu de configurações do editor [[2](https://www.linkedin.com/posts/david-codina-b7b015230_slash-activity-7372112799109586944-MkIX)]. Esta abordagem reflete uma filosofia de design que prioriza a simplicidade, a integração perfeita com o fluxo de trabalho do desenvolvedor e uma curva de aprendizado mais baixa, ao custo de uma menor portabilidade de configuração em comparação com soluções baseadas em arquivos externos.

O conceito central por trás da personalização no Cursor é a ideia de que os comandos slash são simplesmente "gatilhos" que expandem para instruções completas e contextualizadas [[15](https://dev.to/diet-code103/claude-code-is-a-beast-tips-from-6-months-of-hardcore-use-572n)]. Quando um usuário digita um comando slash personalizado, o Cursor não executa uma função pré-compilada ou carrega uma extensão externa. Em vez disso, ele substitui o texto do comando pelo conteúdo de um prompt previamente definido pelo usuário. Isso transforma a criação de um comando personalizado em um exercício de escrita de prompt. O usuário tem total controle sobre o que deseja que aconteça quando o comando for acionado. Por exemplo, em uma discussão no Reddit, um usuário demonstrou a criação de um comando `/debug` que expande para um prompt detalhado sobre como depurar um programa específico, economizando horas de esforço repetitivo [[4](https://www.linkedin.com/posts/jan-hesters_cursor-hack-underrated-create-your-own-activity-7389288658413199361-eMy3)]. Outro exemplo poderia ser a criação de um comando `/commit-message` que pede ao modelo para gerar uma mensagem de commit com base nas mudanças no staging area do Git, utilizando instruções precisas e consistentes [[27](https://stackoverflow.com/questions/79324479/how-to-pass-arguments-to-custom-slash-commands-in-continue-dev)].

A implementação deste mecanismo é realizada através da interface de configuração do Cursor. Dentro das "Configurações do Cursor", o usuário pode navegar para a seção de "User Rules" e definir suas próprias regras [[2](https://www.linkedin.com/posts/david-codina-b7b015230_slash-activity-7372112799109586944-MkIX)]. Uma regra típica seguiria um formato como: "Quando eu uso um dos seguintes comandos slash, substitua-o por este prompt" [[2](https://www.linkedin.com/posts/david-codina-b7b015230_slash-activity-7372112799109586944-MkIX)]. O usuário pode então listar os comandos desejados (por exemplo, `/meu-comando-legal`) e colar o texto completo do prompt que ele deseja que seja inserido no campo de chat. Essa simplicidade é um ponto forte da abordagem do Cursor. Não há necessidade de criar novos arquivos, configurar diretórios específicos ou entender a estrutura de uma extensão. Tudo é gerenciado em um lugar centralizado dentro do editor, mantendo a configuração do assistente de IA integrada ao resto da configuração do desenvolvedor.

Esta abordagem interna tem implicações importantes. Por um lado, ela facilita enormemente a adoção para desenvolvedores que não estão confortáveis com a criação e manutenção de plugins ou que preferem uma experiência totalmente integrada. A personalização se torna tão fácil quanto editar uma configuração. A curva de aprendizado é mínima, pois os desenvolvedores já estão familiarizados com a ideia de escrever prompts para modelagem de linguagem. Por outro lado, essa dependência de configurações internas pode levar a uma menor portabilidade. Se um desenvolvedor precisar migrar sua configuração para uma nova máquina ou compartilhar suas regras de usuário com um colega de equipe, ele precisará exportar e importar as configurações do Cursor, o que pode ser menos conveniente do que simplesmente versionar um diretório de extensões ou arquivos de configuração. Em contraste, uma solução baseada em arquivos externos (como os diretórios `.claude/commands/` ou `.qwen/commands/`) pode ser facilmente adicionada a um repositório Git, tornando a configuração do assistente de IA parte integrante do repositório do projeto e, portanto, versionável e compartilhável.

Apesar da simplicidade do mecanismo, o poder da personalização no Cursor reside na profundidade que pode ser alcançada através dos prompts. Dado que o comando slash é expandido para um prompt completo, o usuário pode encapsular instruções complexas, exemplos de saída desejada, restrições de estilo, e até mesmo referências a partes específicas do códigobase. A discussão comunitária mencionada anteriormente sobre a criação de um comando de depuração salva horas de trabalho, ilustrando como uma única regra bem formulada pode ter um impacto significativo na eficiência [[4](https://www.linkedin.com/posts/jan-hesters_cursor-hack-underrated-create-your-own-activity-7389288658413199361-eMy3)]. O Cursor Hack, uma coletânea de dicas e truques, destaca a criação de comandos slash personalizados como uma funcionalidade pouco explorada, mas extremamente poderosa para aumentar a produtividade [[4](https://www.linkedin.com/posts/jan-hesters_cursor-hack-underrated-create-your-own-activity-7389288658413199361-eMy3)].

É interessante notar que, embora a documentação oficial e os recursos técnicos se concentrem nas "User Rules", a natureza da extensibilidade do Cursor pode ser vista como um tipo de "plugin" em miniatura. Cada "User Rule" é, na essência, uma pequena unidade de lógica personalizada que estende o comportamento padrão do assistente. No entanto, em vez de ser um plugin externo que precisa ser descoberto, instalado e gerenciado separadamente, ele é uma regra aninhada diretamente na configuração do ambiente de trabalho do usuário. Esta integração profunda é o cerne da proposta de valor do Cursor.

Comparando com os modelos de Qwen Code e Claude Code, a abordagem do Cursor é diferente em sua filosofia. Enquanto Qwen Code e Claude Code oferecem um ecossistema de extensões que pode ser compartilhado e gerenciado de forma mais formal, o Cursor foca na personalização individual. A questão não é "como criar uma extensão?", mas sim "como posso configurar meu assistente de IA para que ele faça exatamente o que eu preciso, da maneira que eu quero?". A resposta é a definição de regras de usuário.

Outro aspecto a considerar é a manutenção. Em um sistema baseado em arquivos externos, uma atualização do assistente de IA poderia potencialmente invalidar uma extensão mal construída. No modelo do Cursor, como a personalização é feita inteiramente dentro do editor, ela está sob o controle direto do usuário e não depende de uma API de extensão externa que possa mudar. A versatilidade dos prompts garante que a personalização permaneça relevante, independentemente das atualizações subjacentes do motor de IA do Cursor.

Em suma, o Cursor IDE/CLI oferece um caminho claro e acessível para a extensibilidade de comandos slash através de suas "User Rules". Esta abordagem, embora menos modular e portátil do que os modelos baseados em plugins, compensa com uma integração profunda, simplicidade de uso e um poder de personalização que rivaliza com as soluções mais complexas. Ao transformar a personalização em um exercício de escrita de prompt dentro de uma interface de configuração centralizada, o Cursor torna a extensão de comandos slash um recurso acessível e altamente eficaz para desenvolvedores de todos os níveis de experiência.

## Interoperabilidade como Extensibilidade: A Abordagem do GitHub Copilot via MCP

A abordagem do GitHub Copilot para a extensibilidade de comandos slash representa uma mudança de paradigma em relação aos modelos baseados em plugins ou na criação de comandos internos. Em vez de focar na adição de novos comandos slash por parte do usuário, o Copilot posiciona-se como uma plataforma central cujo poder de extensibilidade vem primariamente de sua capacidade de se conectar e interagir com sistemas, dados e ferramentas externas. O principal vetor dessa extensibilidade é o Model Context Protocol (MCP), um protocolo projetado especificamente para integrar o GitHub Copilot com outros sistemas, enriquecendo assim seu conhecimento e capacidades contextuais [[18](https://docs.github.com/en/copilot/concepts/context/mcp)]. Esta estratégia alinha-se à visão do GitHub de criar um ecossistema de IA aberto e interconectado, onde o Copilot atua como um agente inteligente que pode consultar múltiplas fontes de informação para fornecer respostas mais precisas e realizar tarefas mais complexas.

O MCP é descrito como um protocolo que permite "estender as capacidades do GitHub Copilot integrando-o com outros sistemas" [[18](https://docs.github.com/en/copilot/concepts/context/mcp)]. Em vez de o usuário criar um comando slash personalizado para, por exemplo, "consultar a documentação interna", ele simplesmente faz uma pergunta genérica como "Como utilizo a função X?" e o Copilot, graças à integração via MCP, tem acesso ao contexto relevante da documentação interna da empresa e pode fornecer uma resposta precisa e contextualizada. A extensibilidade, portanto, não é percebida pelo usuário como a criação de um novo comando, mas sim como uma melhoria na qualidade e pertinência das respostas do assistente de IA. A documentação menciona que o Copilot pode ser usado para obter respostas a perguntas de codificação, corrigir erros ou entender o funcionamento de código existente, e a capacidade de enriquecer o contexto através do MCP é fundamental para aprimorar todas essas funcionalidades [[53](https://docs.github.com/copilot/using-github-copilot/asking-github-copilot-questions-in-your-ide), [56](https://docs.github.com/en/copilot/get-started/quickstart)].

A documentação oficial do Copilot Chat menciona a existência de comandos slash, que são usados para evitar a escrita de prompts complexos para cenários comuns [[53](https://docs.github.com/copilot/using-github-copilot/asking-github-copilot-questions-in-your-ide)]. Tipicamente, o usuário digita `/` no prompt para ver a lista de comandos disponíveis, como `/explain` ou `/test` [[53](https://docs.github.com/copilot/using-github-copilot/asking-github-copilot-questions-in-your-ide)]. No entanto, uma análise aprofundada das fontes técnicas fornecidas revela uma lacuna crítica: não há uma documentação clara ou um tutorial sobre como *criar* novos comandos slash personalizados fora dos pré-definidos. A maioria das discussões em fóruns e artigos de blog se concentra em problemas de instalação, como a recomendação de instalar uma versão anterior do Copilot para resolver erros [[16](https://stackoverflow.com/questions/68253302/github-copilot-commands-not-working-and-showing-error)], ou em tutoriais sobre como usar o Copilot CLI para práticas recomendadas [[55](https://docs.github.com/en/copilot/how-tos)]. A falta de um processo documentado para a criação de comandos personalizados sugere que a estratégia do GitHub pode ser deliberada, priorizando a interoperabilidade via MCP em detrimento da personalização de comando direta.

A força do modelo do Copilot reside na capacidade de empresas e desenvolvedores construírem "provedores de contexto" para o MCP. Estes provedores de contexto são como extensões que fornecem dados ao Copilot. Eles podem se conectar a bases de conhecimento, APIs, bancos de dados, ou qualquer outra fonte de dados relevante. Por exemplo, uma organização poderia criar um provedor de contexto que conecta o Copilot ao seu sistema de bilhetes de suporte (como o Jira) e ao seu repositório de documentação. Isso permitiria que um desenvolvedor perguntasse ao Copilot "Qual é o status da correção do erro #12345?" e receberia uma resposta direta, baseada em dados em tempo real, em vez de ter que navegar manualmente entre diferentes sistemas. Esta abordagem é poderosa porque transfere a complexidade da integração para a criação do provedor de contexto, enquanto mantém a interface do usuário do Copilot simples e consistente.

O GitHub Docs menciona a capacidade de adicionar instruções ao repositório, o que influencia o comportamento do Copilot Chat [[55](https://docs.github.com/en/copilot/how-tos)]. Embora não seja a criação de um comando slash, essa capacidade de fornecer contexto de repositório é uma forma de personalização indireta que contribui para a qualidade das respostas. Da mesma forma, o uso de hooks no Copilot CLI permite a automação de fluxos de trabalho, como executar scripts antes ou depois de certas operações, o que amplia o poder do CLI de forma semelhante aos "ganchos" do Claude Code [[55](https://docs.github.com/en/copilot/how-tos)].

A implicação dessa estratégia é que o GitHub Copilot está apostando que a extensibilidade mais valiosa e escalável não virá da criação de comandos ad-hoc pelos usuários finais, mas sim da capacidade de enriquecer o modelo de IA com conhecimento proprietário e especializado. Para uma equipe de desenvolvimento, isso significa que eles podem melhorar continuamente o Copilot para suas necessidades específicas, não criando comandos, mas sim conectando o Copilot a seus dados. Para o ecossistema, isso significa que a comunidade e parceiros podem construir provedores de contexto para nichos específicos (documentação de bibliotecas, padrões de código de indústria, etc.), tornando o Copilot mais útil para uma gama mais ampla de tarefas.

No entanto, essa abordagem pode ser menos intuitiva para um desenvolvedor individual que apenas quer criar um atalho rápido para uma tarefa específica. Em um cenário onde o Qwen Code permite a criação de um comando `/fix-linting` com um simples arquivo de texto, o equivalente no Copilot exigiria a criação de um provedor de contexto para lidar com aquele caso de uso específico. Para muitas tarefas rápidas, a abordagem do Copilot pode parecer excessivamente complexa.

Em conclusão, o GitHub Copilot aborda a extensibilidade de comandos slash de uma maneira que é tanto sua maior força quanto sua maior limitação. Ao centrar sua estratégia em interoperabilidade via Model Context Protocol (MCP), ele oferece um caminho para uma personalização profunda e contextualizada, ideal para equipes e organizações que desejam conectar o assistente de IA a seus sistemas proprietários. No entanto, a ausência de um mecanismo claro e documentado para a criação de comandos slash personalizados para uso geral representa uma lacuna significativa na documentação oficial e pode dificultar a adoção por desenvolvedores que procuram uma solução mais direta e de baixa barreira para personalização. A extensibilidade do Copilot é, portanto, uma extensibilidade de contexto, não de comando.

## Análise de Ferramentas com Informações Incertas: OpenCode, Codex e Gemini CLI

A investigação sobre as capacidades de extensibilidade de comandos slash em três das sete ferramentas listadas — OpenCode, Codex e Gemini CLI — revela um cenário marcado por lacunas significativas de informação nas fontes fornecidas. Embora existam menções isoladas ou sugestões circunstanciais de que essas ferramentas possuem algum tipo de suporte a comandos slash, a documentação oficial e os materiais de pesquisa disponíveis são insuficientes para determinar com certeza os mecanismos, se existirem, que permitem a adição de novos comandos personalizados. Esta seção analisa cada uma dessas ferramentas com base exclusivamente nas pistas encontradas, delineando as incertezas e as conclusões que podem ser extraídas da ausência de dados claros.

**OpenCode**

A evidência sobre o OpenCode é ambígua, mas sugere a existência básica de suporte a comandos slash. A menção mais concreta vem de um pacote NPM chamado `opencode-snippets`, que descreve o uso de `/slash commands` para acionar ações e fluxos de trabalho de forma imperativa [[6](https://libraries.io/npm/opencode-snippets)]. A frase "Use /comandos diagonais para acionar ações e fluxos de trabalho de forma imperativa - qualquer coisa que precise acontecer agora:" seguida por exemplos como `/commit-and-push` e `/add-`, indica que o OpenCode (ou pelo menos a extensão `opencode-snippets`) opera com um sistema de comandos slash que pode disparar ações específicas [[6](https://libraries.io/npm/opencode-snippets)]. Isso confirma que a funcionalidade de identificar e processar comandos iniciados por uma barra (/) existe.

No entanto, a fonte não fornece qualquer detalhe sobre como um usuário pode *adicionar* novos comandos. Não há menção a arquivos de configuração, pastas de extensões, APIs de desenvolvimento ou qualquer outro mecanismo que permita a personalização. A documentação do pacote NPM foca em como usar os comandos existentes, e não em como criá-los. Sem tutoriais, guias de início rápido ou discussões em fóruns que detalhem a criação de comandos personalizados, fica impossível afirmar como a extensibilidade funciona. É plausível que o OpenCode tenha um mecanismo de extensibilidade, dado o contexto da pesquisa que o incluiu na lista. No entanto, ele pode ser:
1.  **Menos popular:** O ecossistema ao redor do OpenCode pode ser pequeno, resultando em pouca documentação ou discussão comunitária.
2.  **Menos maduro:** A funcionalidade de extensibilidade pode estar presente, mas não ser um foco principal da documentação, sendo tratada como um recurso secundário.
3.  **Limitada:** A extensibilidade pode ser inexistente ou muito restrita, permitindo apenas o uso dos comandos pré-definidos pelo desenvolvedor da extensão.

A conclusão mais segura, com base nos materiais fornecidos, é que, embora o OpenCode utilize comandos slash, os métodos para sua extensão ou personalização não foram documentados ou discutidos nas fontes analisadas. Uma investigação mais aprofundada na documentação oficial do projeto OpenCode e em seu repositório de código-fonte seria necessária para preencher essa lacuna.

**Codex**

A situação com o Codex é ainda mais incerta. A única menção a ele como tendo suporte a comandos slash provém de uma discussão em um fórum, onde um usuário menciona "Eu uso OpenCode. Vejo o suporte a comandos slash, legal! E quanto à tabulação para alternar modos?..." [[5](https://forum.obsidian.md/t/new-plugin-agent-client-bring-claude-code-codex-gemini-cli-inside-obsidian/108448)]. Esta observação, feita por um membro da comunidade, é a única evidência encontrada nas fontes fornecidas que conecta o Codex a essa funcionalidade. Ela é, no entanto, anedótica e não substantiva.

Crucialmente, o Codex não é mencionado em nenhum dos links de documentação técnica ou artigos de blog fornecidos. Não há documentação oficial do Codex nas fontes, nem análises comparativas que explorem suas características. A palavra "Codex" aparece em discussões sobre a instalação do GitHub Copilot, mas não como um produto separado [[16](https://stackoverflow.com/questions/68253302/github-copilot-commands-not-working-and-showing-error), [56](https://docs.github.com/en/copilot/get-started/quickstart)]. A ausência total de documentação técnica sobre como o Codex funciona impede qualquer análise substancial sobre sua capacidade de extensibilidade de comandos slash. Existem várias possibilidades:
1.  **Confusão de Nomenclatura:** O usuário do fórum pode estar usando o termo "Codex" incorretamente, possivelmente se referindo a outro produto da OpenAI ou a uma funcionalidade genérica de assistente de IA.
2.  **Produto Descontinuado ou Menor:** O Codex pode ser um produto menos conhecido ou que não recebeu o mesmo nível de atenção da comunidade e da documentação em comparação com o GPT-3, do qual ele é uma versão especializada.
3.  **Suporte Inexistente:** É possível que o Codex não tenha suporte a comandos slash, e a menção no fórum seja um equívoco.

Sem fontes confiáveis que definam o que é o Codex e como ele opera, não é possível fazer uma avaliação informada sobre sua capacidade de adicionar comandos slash. A conclusão deve ser de incerteza total, com base apenas na menção comunitária isolada e na ausência completa de documentação técnica.

**Gemini CLI**

O Gemini CLI apresenta um caso intrigante de lacuna de informação. A evidência mais promissora é o título de um artigo: "Guia Completo para Extensões do Gemini CLI" [[1](https://dev.to/sienna/gemini-cli-extensions-the-complete-developers-guide-to-ai-powered-command-line-customization-g2b)]. Este título sugere fortemente que a extensibilidade via plugins ou extensões é uma funcionalidade central e proeminente do Gemini CLI. A própria menção de "extensões" implica um mecanismo para que os usuários adicionem novas funcionalidades, o que naturalmente incluiria a capacidade de adicionar novos comandos slash.

No entanto, este título é a única menção à extensibilidade do Gemini CLI nas fontes fornecidas. Nenhuma outra fonte — seja documentação técnica, artigos de blog ou fóruns — detalha como essas "extensões" funcionam, quais são os requisitos para criar uma ou como elas se relacionam com a criação de comandos slash. A investigação se depara com um vácuo de informações. É razoável inferir, com base no título do artigo, que o Gemini CLI possui um sistema de extensibilidade, possivelmente semelhante aos de Qwen Code ou Claude Code, que poderia envolver a criação de plugins, a edição de arquivos de configuração ou a utilização de uma API de desenvolvedor.

As conclusões possíveis são:
1.  **Extensibilidade Explícita:** O Gemini CLI possui um sistema de extensões bem definido, mas a documentação sobre ele não foi incluída nas fontes fornecidas. A análise se baseia apenas no título do artigo, sem poder confirmar ou detalhar os mecanismos.
2.  **Extensibilidade Implícita:** O termo "extensões" pode ser usado de forma mais geral para descrever a capacidade do CLI de trabalhar com diferentes modelos de linguagem ou backends, e não necessariamente um sistema de plugins para comandos slash.
3.  **Marketing vs. Realidade:** O título do artigo pode ser otimista, prometendo uma funcionalidade que não está totalmente desenvolvida ou documentada nas fontes analisadas.

Portanto, a análise sobre o Gemini CLI deve ser qualificada. A existência de um mecanismo de extensibilidade é alta, mas os detalhes sobre como ele permite a adição de comandos slash permanecem desconhecidos. A recomendação lógica seria buscar a documentação específica sobre "Gemini CLI Extensions" para preencher essa lacuna crítica.

Em resumo, para as ferramentas OpenCode, Codex e Gemini CLI, a pesquisa revela que a informação disponível é insuficiente para uma conclusão definitiva. OpenCode mostra sinais de suporte a comandos slash, mas a extensibilidade é obscura. Codex é mencionado apenas uma vez e sem contexto técnico. Gemini CLI tem um título promissor que sugere extensibilidade, mas nenhum detalhe técnico subsequente. Para essas três ferramentas, a ausência de informação é um resultado válido, indicando áreas onde a pesquisa seria inconclusiva sem acesso a fontes adicionais.

## Síntese Comparativa e Implicações Estratégicas

A investigação aprofundada sobre a capacidade de extensão de comandos slash nas principais ferramentas de CLI de IA revela um panorama diversificado de abordagens, desde modelos de extensibilidade avançada baseados em plugins até estratégias de customização integrada e modelos focados em interoperabilidade. A análise comparativa das sete ferramentas listadas — Gemini CLI, Claude Code, Qwen Code, Cursor IDE/CLI, OpenCode, Codex e GitHub Copilot — demonstra que não há uma única resposta para a pergunta de como adicionar comandos personalizados. Em vez disso, as ferramentas refletem diferentes filosofias de design e estratégias de mercado, cada uma com suas próprias vantagens e públicos-alvo. A tabela a seguir sintetiza os achados para cada ferramenta, consolidando os mecanismos de extensibilidade identificados e as lacunas de informação.

| Ferramenta | Mecanismo de Extensibilidade Primário | Métricas-Chave e Fontes | Nível de Acesso |
| :--- | :--- | :--- | :--- |
| **Qwen Code** | Sistema de Extensões (Plugins) e Comandos via Markdown | Arquivos `.qwen/commands/*.md` [[13](https://qwenlm.github.io/qwen-code-docs/zh/developers/extensions/getting-started-extensions/)]; Gerenciamento via `/extensions` com recarga em tempo real [[14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)]; Suporte a MCP para integrações [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/)]. | Alto |
| **Claude Code** | Híbrido: Skills e Comandos via Markdown | Diretórios `.claude/commands/*.md` [[69](https://docs.anthropic.com/en/release-notes/claude-code)]; Arquivos `CLAUDE.md` para contexto [[10](https://docs.anthropic.com/en/docs/claude-code/sdk)]; Hooks para automação [[8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)]. | Alto |
| **Cursor IDE/CLI** | Configurações Internas (User Rules) | Definição de regras de usuário para mapear comandos a prompts completos [[2](https://www.linkedin.com/posts/david-codina-b7b015230_slash-activity-7372112799109586944-MkIX)]. | Médio-Alto |
| **GitHub Copilot** | Interoperabilidade via Model Context Protocol (MCP) | Enriquecimento de contexto ao se conectar a sistemas externos [[18](https://docs.github.com/en/copilot/concepts/context/mcp)]. A criação de comandos slash personalizados não é documentada. | Baixo (para usuário final) |
| **OpenCode** | Incerta / Não Documentada | Menção ao uso de `/slash commands` [[6](https://libraries.io/npm/opencode-snippets)], mas sem detalhes sobre como criar novos. | Incerto |
| **Codex** | Incerta / Não Documentada | Mencionado em fórum como tendo suporte [[5](https://forum.obsidian.md/t/new-plugin-agent-client-bring-claude-code-codex-gemini-cli-inside-obsidian/108448)], mas sem documentação técnica. | Incerto |
| **Gemini CLI** | Incerta / Não Documentada | Título de artigo sugere extensões [[1](https://dev.to/sienna/gemini-cli-extensions-the-complete-developers-guide-to-ai-powered-command-line-customization-g2b)], mas sem detalhes técnicos sobre sua implementação. | Incerto |

Com base nesta síntese, é possível categorizar as ferramentas em três modelos distintos de extensibilidade, cada um com implicações estratégicas para os desenvolvedores e equipes que as adotam.

O primeiro modelo é o de **Plataformas de Extensibilidade Avançada**, representado principalmente por **Qwen Code** e **Claude Code**. Estas plataformas oferecem múltiplos caminhos para a personalização, priorizando a modularidade e a interoperabilidade. O Qwen Code, em particular, apresenta um sistema robusto e bem documentado, com um ecossistema de extensões que suporta desde comandos simples baseados em Markdown até integrações complexas com servidores MCP [[48](https://qwenlm.github.io/qwen-code-docs/en/developers/tools/mcp-server/), [49](https://qwenlm.github.io/qwen-code-docs/en/developers/architecture/)]. A capacidade de gerenciar essas extensões dinamicamente via comando `/extensions` com recarga em tempo real é uma vantagem competitiva significativa para a produtividade [[14](https://qwenlm.github.io/qwen-code-docs/zh/users/extension/introduction/)]. O Claude Code segue uma abordagem semelhante, combinando um sistema de "Skills" para compartilhamento de conhecimento com um método mais acessível baseado em Markdown, além de recursos de automação como "Hooks" [[7](https://docs.anthropic.com/en/docs/claude-code/skills), [8](https://docs.anthropic.com/en/docs/claude-code/hooks-guide)]. Para equipes e desenvolvedores que buscam construir soluções personalizadas, robustas e integráveis a ecossistemas maiores, este modelo é ideal. Ele concede um controle granular sobre o comportamento do assistente de IA, permitindo a criação de um ambiente de trabalho altamente otimizado para tarefas específicas.

O segundo modelo é o de **Plataformas de Customização Integrada**, com o **Cursor IDE/CLI** como seu principal exponente. Esta abordagem se distingue por mover a personalização para dentro do próprio ambiente de trabalho do desenvolvedor, utilizando "User Rules" para mapear comandos slash a prompts personalizados [[2](https://www.linkedin.com/posts/david-codina-b7b015230_slash-activity-7372112799109586944-MkIX)]. A simplicidade deste método é sua principal virtude; não há necessidade de criar e gerenciar extensões externas, o que reduz a curva de aprendizado e integra a personalização diretamente ao fluxo de trabalho. O poder reside na capacidade de encapsular instruções complexas em um único comando, tornando-a altamente eficaz para automação de tarefas recorrentes [[15](https://dev.to/diet-code103/claude-code-is-a-beast-tips-from-6-months-of-hardcore-use-572n)]. No entanto, essa conveniência vem com a troca de uma menor portabilidade e versionamento das configurações em comparação com os modelos baseados em arquivos. Este modelo é ideal para desenvolvedores individuais ou pequenas equipes que valorizam a simplicidade e a integração perfeita com seu editor de código, preferindo uma experiência "aparelhada" a um ecossistema de plugins externo.

O terceiro modelo é o de **Plataformas de Interoperabilidade**, exemplificado pelo **GitHub Copilot**. A estratégia do Copilot não é incentivar a criação de comandos slash personalizados pelo usuário final, mas sim enriquecer o contexto do modelo através do Model Context Protocol (MCP) [[18](https://docs.github.com/en/copilot/concepts/context/mcp)]. Ao permitir que o Copilot se conecte a sistemas e dados externos, a extensibilidade é alcançada indiretamente, melhorando a qualidade e a pertinência das respostas. Esta é uma abordagem poderosa para organizações que desejam conectar o assistente de IA ao seu conhecimento proprietário e sistemas legados. No entanto, para um desenvolvedor individual que busca criar um atalho rápido, o processo pode parecer excessivamente complexo. A ausência de documentação clara sobre a criação de comandos personalizados é uma lacuna significativa [[53](https://docs.github.com/copilot/using-github-copilot/asking-github-copilot-questions-in-your-ide)]. Este modelo é mais adequado para cenários empresariais e de integração profunda do que para a customização rápida e individual.

Finalmente, as ferramentas **OpenCode**, **Codex** e **Gemini CLI** permanecem em uma categoria de incerteza. A falta de informações suficientes impede uma classificação precisa. OpenCode mostra sinais de suporte a comandos slash, mas a extensibilidade é obscura [[6](https://libraries.io/npm/opencode-snippets)]. Codex é mencionado apenas uma vez, sem contexto técnico [[5](https://forum.obsidian.md/t/new-plugin-agent-client-bring-claude-code-codex-gemini-cli-inside-obsidian/108448)]. Gemini CLI tem um título promissor que sugere extensões, mas nenhum detalhe técnico [[1](https://dev.to/sienna/gemini-cli-extensions-the-complete-developers-guide-to-ai-powered-command-line-customization-g2b)]. A ausência de dados para estas ferramentas é, por si só, uma conclusão relevante, indicando que a pesquisa seria inconclusiva sem acesso a fontes adicionais.

Em última análise, a escolha da ferramenta de CLI de IA mais adequada depende do perfil do usuário e de suas necessidades de personalização. Para quem busca máxima flexibilidade e controle, Qwen Code e Claude Code oferecem os caminhos mais robustos. Para quem valoriza simplicidade e integração, o Cursor é a escolha superior. Para quem opera em um ambiente corporativo e busca enriquecer o contexto do modelo com dados proprietários, o GitHub Copilot representa a visão de futuro. A tendência geral, contudo, é clara: as interfaces de linha de comando de IA estão evoluindo rapidamente de ferramentas fechadas para plataformas abertas e extensíveis, e a capacidade de personalizar comandos slash tornou-se um diferencial competitivo fundamental.